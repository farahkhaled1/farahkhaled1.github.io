{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "print(nlp.Defaults.stop_words)\n",
    "\n",
    "nlp.vocab['myself'].is_stop\n",
    "\n",
    "nlp.vocab['mystery'].is_stop\n",
    "\n",
    "nlp.vocab['btw'].is_stop\n",
    "\n",
    "nlp.Defaults.stop_words.add('btw')\n",
    "nlp.vocab['btw'].is_stop = True\n",
    "\n",
    "nlp.vocab['btw'].is_stop\n",
    "\n",
    "\n",
    "\n",
    "nlp.vocab['beyond'].is_stop\n",
    "\n",
    "nlp.Defaults.stop_words.remove('beyond')\n",
    "nlp.vocab['beyond'].is_stop = False\n",
    "\n",
    "nlp.vocab['beyond'].is_stop\n",
    "\n",
    "\n",
    "\n",
    "my_sw = ['i','he','she','it','my','your','his','him','her']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "print(len(stop_words))\n",
    "stop_words\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "example_sent = \"This is a sample sentence, And This showing off the stop words filtration.\"\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "word_tokens = word_tokenize(example_sent)\n",
    "word_tokens\n",
    "\n",
    "filtered_sentence = [w for w in word_tokens]\n",
    "\n",
    "print(word_tokens)\n",
    "print('---------------------------------')\n",
    "print(filtered_sentence)\n",
    "\n",
    "filtered_sentence = [w for w in word_tokens if not w in stop_words]\n",
    "\n",
    "print(word_tokens)\n",
    "print('---------------------------------')\n",
    "print(filtered_sentence)\n",
    "\n",
    "filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]\n",
    "\n",
    "print(word_tokens)\n",
    "print('---------------------------------')\n",
    "print(filtered_sentence)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Ar_SW1 = set(nltk.corpus.stopwords.words(\"arabic\"))\n",
    "print(len(Ar_SW1))\n",
    "' | '.join(Ar_SW1)\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "Ar_SW2 = stopwords.words('arabic')\n",
    "print(len(Ar_SW2))\n",
    "' | '.join(Ar_SW2)\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "#config the language\n",
    "stop_words = stopwords.words('arabic')\n",
    "\n",
    "print(stop_words)\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "mytext = \" هذا هو أول مثال لي في المدرسة \"\n",
    "\n",
    "\n",
    "stop_words = set(stopwords.words('arabic'))\n",
    "\n",
    "\n",
    "words = word_tokenize(mytext)\n",
    "\n",
    "\n",
    "filtered_words = []\n",
    "\n",
    "\n",
    "for word in words:\n",
    "    if word not in stop_words:\n",
    "        filtered_words.append(word)\n",
    "\n",
    "\n",
    "print(filtered_words)\n",
    "\n",
    "# pip install arabicstopwords\n",
    "# pip install pyarabic\n",
    "# import pyarabic.araby as araby\n",
    "# import pyarabic.number as number\n",
    "\n",
    "# pip install arabicstopwords\n",
    "# import arabicstopwords.arabicstopwords as stp\n",
    "# import arabicstopwords as stp\n",
    "# import nltk\n",
    "# from nltk.corpus import stopwords\n",
    "# stops = set(stopwords.words('Arabic'))\n",
    "\n",
    "\n",
    "# len(stp.classed_stopwords_list())\n",
    "\n",
    "# stp.classed_stopwords_list()\n",
    "\n",
    "# len(stp.stopwords_list())\n",
    "\n",
    "# stp.stopwords_list()\n",
    "\n",
    "\n",
    "\n",
    "# stp.is_stop(u'ممكن')\n",
    "\n",
    "# stp.is_stop(u'منكم')\n",
    "\n",
    "# stp.stopword_forms(u\"على\")\n",
    "\n",
    "# len(stp.stopword_forms(u\"على\"))\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
