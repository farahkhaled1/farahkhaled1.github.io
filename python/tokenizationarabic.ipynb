{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -U spacy\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "doc = nlp('Tesla is looking at buying U.S. startup for $69 million')\n",
    "\n",
    "type(doc)\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text)\n",
    "#     print(token.shape)\n",
    "    print(token.shape_)\n",
    "    print(token.is_alpha)\n",
    "#     print(token.is_stop)\n",
    "    print('---------------')\n",
    "\n",
    "doc[0] , doc[1] , doc[2] , doc[3] , doc[4] , doc[5] , doc[6] , doc[7] , \n",
    "\n",
    "\n",
    "\n",
    "doc2 = nlp('''\n",
    "Although commmonly attributed to John Lennon from his song \"Beautiful Boy\",\n",
    "the phrase \"Life is what happens to us while we are making other plans\" was written by cartoonist Allen Saunders and\n",
    "published in Reader\\'s Digest in 1957, when Lennon was 17.    \n",
    "''')\n",
    "\n",
    "life_quote = doc2[19:31]\n",
    "print(life_quote)\n",
    "\n",
    "\n",
    "\n",
    "mystring = '\"We\\'re moving to L.A.!\"'\n",
    "print(mystring)\n",
    "\n",
    "doc3 = nlp(mystring)\n",
    "\n",
    "for token in doc3:\n",
    "    print(token.text, end=' | ')\n",
    "\n",
    "\n",
    "\n",
    "doc4 = nlp(u\"We're here to help! Send snail-mail, email support@oursite.com or visit us at http://www.oursite.com!\")\n",
    "\n",
    "for token in doc4:\n",
    "    print(token)\n",
    "\n",
    "doc5 = nlp(u'A 5km NYC cab ride costs $10.30')\n",
    "\n",
    "for token in doc5:\n",
    "    print(token)\n",
    "\n",
    "doc6 = nlp(u\"Let's visit St. Louis in the U.S. next year.\")\n",
    "\n",
    "for token in doc6:\n",
    "    print(token)\n",
    "\n",
    "doc7 = nlp(u'My dinner was horrible.')\n",
    "doc8 = nlp(u'Your dinner was delicious.')\n",
    "\n",
    "# Try to change \"My dinner was horrible\" to \"My dinner was delicious\"\n",
    "# doc7[3] = doc8[3]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from nltk.tokenize import  word_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "EXAMPLE_TEXT = \"\"\"\n",
    "Hello Mr. Smith, how are you doing today? The weather is great, \n",
    "and Python is awesome. The sky is pinkish-blue. You shouldn't eat cardboard.\n",
    "\"\"\"\n",
    "\n",
    "print(word_tokenize(EXAMPLE_TEXT))\n",
    "\n",
    "\n",
    "\n",
    "EXAMPLE_TEXT = '''\n",
    "Thomas Gradgrind, sir.  A man of realities.  A man of facts and calculations.  A man who proceeds upon the principle that two and two are four, and nothing over, and who is not to be talked into allowing for anything over.  Thomas Gradgrind, sir—peremptorily Thomas—Thomas Gradgrind.  With a rule and a pair of scales, and the multiplication table always in his pocket, sir, ready to weigh and measure any parcel of human nature, and tell you exactly what it comes to.  It is a mere question of figures, a case of simple arithmetic.  You might hope to get some other nonsensical belief into the head of George Gradgrind, or Augustus Gradgrind, or John Gradgrind, or Joseph Gradgrind (all supposititious, non-existent persons), but into the head of Thomas Gradgrind—no, sir!\n",
    "In such terms Mr. Gradgrind always mentally introduced himself, whether to his private circle of acquaintance, or to the public in general.  In such terms, no doubt, substituting the words ‘boys and girls,’ for ‘sir,’ Thomas Gradgrind now presented Thomas Gradgrind to the little pitchers before him, who were to be filled so full of facts.\n",
    "Indeed, as he eagerly sparkled at them from the cellarage before mentioned, he seemed a kind of cannon loaded to the muzzle with facts, and prepared to blow them clean out of the regions of childhood at one discharge.  He seemed a galvanizing apparatus, too, charged with a grim mechanical substitute for the tender young imaginations that were to be stormed away.\n",
    "‘Girl number twenty,’ said Mr. Gradgrind, squarely pointing with his square forefinger, ‘I don’t know that girl.  Who is that girl?’\n",
    "'''\n",
    "\n",
    "print(word_tokenize(EXAMPLE_TEXT))\n",
    "\n",
    "\n",
    "\n",
    "for line in EXAMPLE_TEXT.split('\\n')[:20] :\n",
    "    print(line.split()[:10])\n",
    "    print('------------------------')\n",
    "    print(word_tokenize(line)[:10])\n",
    "    print('====================================================')    \n",
    "\n",
    "\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "doc = nlp(' يعد الذكاء الإصطناعي من العلوم التي يتسارع التطور فيها بشكل لافت منذ عام 2005 و لمدة 15 سنة ')\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text)\n",
    "    print(token.shape_)\n",
    "    print(token.is_alpha)\n",
    "    print(token.is_stop)\n",
    "    print('---------------')\n",
    "\n",
    "doc[0] , doc[1] , doc[2] , doc[3] , doc[4] , doc[5] , doc[6] , doc[7] \n",
    "\n",
    "\n",
    "\n",
    "doc2 = nlp('''\n",
    "أبو عبد الله محمد بن موسى الخوارزمي عالم رياضيات وفلك\n",
    "وجغرافيا مسلم. يكنى باسم الخوارزمي وأبي جعفر. قيل أنه ولد حوالي 164هـ 781م (وهو غير مؤكد) وقيل أنه توفي بعد 232 هـ أي (بعد 847م). يعتبر\n",
    "من أوائل علماء الرياضيات المسلمين حيث ساهمت أعماله بدور كبير في تقدم الرياضيات في عصره. اتصل بالخليفة العباسي المأمون وعمل في بيت الحكمة في \n",
    "بغداد وكسب ثقة الخليفة إذ ولاه المأمون بيت الحكمة كما عهد إليه برسم خارطة للأرض عمل فيها أكثر من سبعين جغرافيا. قبل وفاته في 850 م/232 هـ\n",
    "كان الخوارزمي قد ترك العديد من المؤلفات في علوم الرياضيات والفلك والجغرافيا ومن أهمها كتاب المختصر في حساب الجبر والمقابلة الذي يعد أهم كتبه\n",
    "\n",
    "''')\n",
    "\n",
    "life_quote = doc2[15:33]\n",
    "print(life_quote)\n",
    "\n",
    "\n",
    "\n",
    "doc4 = nlp(u\"يمكنك مراسلتنا علي البريد الإلكتروني للشركة هو info@hp.com   او تصفح موقع الشركة وهو www.hp.com \")\n",
    "\n",
    "for token in doc4:\n",
    "    print(token)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from nltk.tokenize import  word_tokenize\n",
    "\n",
    "EXAMPLE_TEXT = \"\"\"\n",
    "أبو عبد الله محمد بن موسى الخوارزمي عالم رياضيات وفلك\n",
    "وجغرافيا مسلم. يكنى باسم الخوارزمي وأبي جعفر. قيل أنه ولد حوالي 164هـ 781م (وهو غير مؤكد) وقيل أنه توفي بعد 232هـ أي (بعد 847م). يعتبر\n",
    "من أوائل علماء الرياضيات المسلمين حيث ساهمت أعماله بدور كبير في تقدم الرياضيات في عصره. اتصل بالخليفة العباسي المأمون وعمل في بيت الحكمة في \n",
    "بغداد وكسب ثقة الخليفة إذ ولاه المأمون بيت الحكمة كما عهد إليه برسم خارطة للأرض عمل فيها أكثر من سبعين جغرافيا. قبل وفاته في 850 م/232 هـ\n",
    "كان الخوارزمي قد ترك العديد من المؤلفات في علوم الرياضيات والفلك والجغرافيا ومن أهمها\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "print(word_tokenize(EXAMPLE_TEXT))\n",
    "\n",
    "for line in EXAMPLE_TEXT.split('\\n')[:20] :\n",
    "    print(line.split()[:10])\n",
    "    print('------------------------')\n",
    "    print(word_tokenize(line)[:10])\n",
    "    print('====================================================')\n",
    "#     x=word_tokenize(line)\n",
    "for z in word_tokenize(line):\n",
    "  print(z) \n",
    "\n",
    "from nltk.stem.porter import *\n",
    "p_stemmer = PorterStemmer()\n",
    "words = ['الجري','تجري','يجرون','جري','يجري']\n",
    "for word in words:\n",
    "    print(word+' --> '+p_stemmer.stem(word))\n",
    "    \n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "s_stemmer = SnowballStemmer(language='arabic')\n",
    "\n",
    "words = ['الجري','تجري','يجرون','جري','يجري']\n",
    "for word in words:\n",
    "    print(word+' --> '+s_stemmer.stem(word))\n",
    "\n",
    "words = ['الجري','تجري','يجرون','جري','يجري']\n",
    "\n",
    "for word in words:\n",
    "    print(word+' --> '+s_stemmer.stem(word))\n",
    "\n",
    "from nltk.stem import PorterStemmer , LancasterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "ps = PorterStemmer()\n",
    "ls =  LancasterStemmer()\n",
    "\n",
    "words = ['الجري','تجري','يجرون','جري','يجري']\n",
    "\n",
    "for w in words:\n",
    "    print(ps.stem(w))\n",
    "\n",
    "for w in words:\n",
    "    print(ls.stem(w))\n",
    "\n",
    "words = ['الجري','تجري','يجرون','جري','يجري']\n",
    "print(\"{0:20}{1:20}{2:20}\".format(\"Word\",\"Porter Stemmer\",\"lancaster Stemmer\"))\n",
    "for word in words:\n",
    "    print(\"{0:20}{1:20}{2:20}\".format(word,ps.stem(word),ls.stem(word)))\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "words = ['الجري','تجري','يجرون','جري','يجري']\n",
    "\n",
    "for word in words : \n",
    "  print(lemmatizer.lemmatize(word))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "text = \"Tesla is looking at buying U.S. startup for $6 million\"\n",
    "\n",
    "text.split()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
